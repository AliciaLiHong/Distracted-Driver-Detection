{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image  # uses pillow\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(640, 480)\n"
     ]
    }
   ],
   "source": [
    "image_file = \"imgs/train/c0/img_34.jpg\"\n",
    "im = Image.open(image_file)\n",
    "print im.size   # return value is a tuple, ex.: (640, 480)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(640, 480)\n"
     ]
    }
   ],
   "source": [
    "image_file = \"imgs/train/c3/img_5.jpg\"\n",
    "im = Image.open(image_file)\n",
    "print im.size   # return value is a tuple, ex.: (1200, 800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#from tqdm import tqdm\n",
    "import tqdm\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[44 44 44 ..., 27 30 83]\n",
      " [44 44 44 ..., 24 27 79]\n",
      " [44 44 44 ..., 23 28 76]\n",
      " ..., \n",
      " [ 5  6  6 ..., 17 17 16]\n",
      " [ 5  6  6 ..., 18 17 16]\n",
      " [ 5  6  6 ..., 18 17 15]]\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread(image_file, 0)\n",
    "print img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cv2.namedWindow(\"Image\")\\ncv2.imshow(\"Image\", img) \\ncv2.waitKey (0)  \\ncv2.destroyAllWindows() '"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''cv2.namedWindow(\"Image\")\n",
    "cv2.imshow(\"Image\", img) \n",
    "cv2.waitKey (0)  \n",
    "cv2.destroyAllWindows() '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "\n",
    "from keras.models import *\n",
    "from keras.applications import *\n",
    "from keras.layers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "height = 299\n",
    "n = 10  # the size of the whole training set\n",
    "y = np.zeros((n, 10), dtype=np.uint8) #\n",
    "X = np.zeros((n, height, height, 3), dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2489\n"
     ]
    }
   ],
   "source": [
    "# For all kind of files, subdirectories included:\n",
    "import os\n",
    "list = os.listdir('imgs/train/c0') # dir is your directory path\n",
    "number_files = len(list)\n",
    "print number_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the size of the whole training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2489\n"
     ]
    }
   ],
   "source": [
    "#Only files (avoiding subdirectories):\n",
    "import os\n",
    "\n",
    "onlyfiles = next(os.walk('imgs/train/c0/'))[2] #dir is your directory path as string\n",
    "print len(onlyfiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22424\n"
     ]
    }
   ],
   "source": [
    "n = 0\n",
    "for i in range(10):\n",
    "    files = next(os.walk('imgs/train/c%d/'%i))[2]\n",
    "    n += len(files)\n",
    "\n",
    "print n   \n",
    "# this is right!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = cv2.imread()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "from os import listdir, makedirs\n",
    "from os.path import join, exists, expanduser\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications import xception\n",
    "from keras.applications import inception_v3\n",
    "from keras.applications.vgg16 import preprocess_input, decode_predictions\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "compare_loss={}\n",
    "compare_accuracy={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to convert image to array\n",
    "def read_img(address, size):\n",
    "    '''Read and resize image.\n",
    "    Return image as numpy array, by normalizing the values'''\n",
    "    img = image.load_img(address, target_size = size)\n",
    "    img = image.img_to_array(img)\n",
    "    return img\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to convert labels to one hot encoding vector\n",
    "def OneHotEncoded(y_train):\n",
    "    y_t=np.zeros((len(y_train),Num_Class), dtype=int)\n",
    "    for i,x in enumerate(y_train):\n",
    "        #y_t[i][int(x)-1]=1\n",
    "        y_t[i][int(x)] = 1\n",
    "    return y_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inception.ipynb            test.csv\r\n",
      "Original.ipynb             train_i_bf.npy\r\n",
      "README.md                  train_i_bf_.npy\r\n",
      "\u001b[34mTutorial\u001b[m\u001b[m/                  train_vgg_bf.npy\r\n",
      "VGG.ipynb                  train_x_bf.npy\r\n",
      "Xception.ipynb             train_x_bf_.npy\r\n",
      "driver_imgs_list.csv       valid_i_bf.npy\r\n",
      "driver_imgs_list.csv.zip   valid_i_bf_.npy\r\n",
      "\u001b[34mimgs\u001b[m\u001b[m/                      valid_vgg_bf.npy\r\n",
      "imgs.zip                   valid_x_bf.npy\r\n",
      "labels.csv                 valid_x_bf_.npy\r\n",
      "merge.ipynb                x_test.npy\r\n",
      "\u001b[34mreports\u001b[m\u001b[m/                   x_train.npy\r\n",
      "sample_submission.csv      y_train.npy\r\n",
      "sample_submission.csv.zip\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "from shutil import copy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SIZE = 224\n",
    "directory_lists=os.listdir(\"./imgs/train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.DS_Store', 'c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9']\n"
     ]
    }
   ],
   "source": [
    "print(directory_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    }
   ],
   "source": [
    "print(len(directory_lists))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 20] Not a directory: './imgs/train/.DS_Store'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-92cadf060476>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory_lists\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m                        \u001b[0;31m#'''directory_lists == files in /train == ['c0', 'c1', ... , 'c9']'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdirectory_lists\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mimag\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./imgs/train/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory_lists\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m     \u001b[0;31m#'''imag == files in /train/c# '''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mcurrent_loc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"./imgs/train/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory_lists\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m    \u001b[0;31m#'''./imgs/train/c#/'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 20] Not a directory: './imgs/train/.DS_Store'"
     ]
    }
   ],
   "source": [
    "labels = {}\n",
    "data = {}\n",
    "\n",
    "with open('./labels.csv', 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['id','class'])\n",
    "    for i in range(0, len(directory_lists)):                        #'''directory_lists == files in /train == ['c0', 'c1', ... , 'c9']'''\n",
    "        t = directory_lists[i][1:]\n",
    "        imag=os.listdir(\"./imgs/train/\"+str(directory_lists[i]))     #'''imag == files in /train/c# '''\n",
    "        current_loc = \"./imgs/train/\"+str(directory_lists[i])+\"/\"    #'''./imgs/train/c#/'''\n",
    "        for k in range(0, len(imag)):\n",
    "            x=[current_loc+str(imag[k])]+[t]\n",
    "            writer.writerow(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##change here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "from shutil import copy2\n",
    "directory_lists=os.listdir(\"./imgs/test\")\n",
    "with open('./test.csv', 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['id'])\n",
    "    for i in range(0, len(directory_lists)):                        #'''directory_lists == files in /train == ['c0', 'c1', ... , 'c9']'''\n",
    "        x=[\"./imgs/test/\"+directory_lists[i]]\n",
    "        writer.writerow(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './'\n",
    "labels = pd.read_csv(join(data_dir, 'labels.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22424it [02:43, 137.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Images shape: (22424, 224, 224, 3) size: 3,375,439,872\n"
     ]
    }
   ],
   "source": [
    "INPUT_SIZE = 224\n",
    "POOLING = 'avg'\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "x_train = np.zeros((len(labels), INPUT_SIZE, INPUT_SIZE, 3), dtype='float32')\n",
    "y_train= np.zeros((len(labels),), dtype='float32')\n",
    "\n",
    "for i, img_id in tqdm(enumerate(labels['id'])):\n",
    "    img = read_img(img_id, (INPUT_SIZE, INPUT_SIZE))\n",
    "    x = preprocess_input(np.expand_dims(img.copy(), axis=0))\n",
    "    x_train[i] = x\n",
    "    y_train[i]=int(labels['class'][i])\n",
    "print('Train Images shape: {} size: {:,}'.format(x_train.shape, x_train.size))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "change here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "975it [00:05, 163.67it/s]"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv(join('./', 'test.csv'))\n",
    "\n",
    "INPUT_SIZE = 224\n",
    "POOLING = 'avg'\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "x_test = np.zeros((len(test), INPUT_SIZE, INPUT_SIZE, 3), dtype='float32')\n",
    "\n",
    "for i, img_id in tqdm(enumerate(test['id'])):\n",
    "    img = read_img(img_id, (INPUT_SIZE, INPUT_SIZE))\n",
    "    x = preprocess_input(np.expand_dims(img.copy(), axis=0))\n",
    "    x_test[i] = x\n",
    "print('Test Images shape: {} size: {:,}'.format(x_test.shape, x_test.size))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(open('x_train.npy', 'w'), x_train)\n",
    "np.save(open('y_train.npy', 'w'), y_train)\n",
    "np.save(open('x_test.npy', 'w'), x_test)\n",
    "\n",
    "'''\n",
    "#print(x_train)\n",
    "for i in range(0, 22424, 1000):\n",
    "    print(y_train[i])\n",
    "print(len(y_train))\n",
    "\n",
    "# y_train is int, why here is float\n",
    "for i in range(0, len(x_test), 1000):\n",
    "    print(x_test[i])\n",
    "print(len(x_test))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Num_Class=10  # number of classes in dataset\n",
    "# convert labels to one hot encoding\n",
    "y_train=OneHotEncoded(y_train)\n",
    "# split data in to training and validation set\n",
    "X_train, X_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.33, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''base_model = ResNet50(input_tensor=Input((224, 224, 3)), weights='imagenet', include_top=False)\n",
    "\n",
    "for layers in base_model.layers:\n",
    "    layers.trainable = False\n",
    "\n",
    "x = GlobalAveragePooling2D()(base_model.output)\n",
    "x = Dropout(0.25)(x)\n",
    "x = Dense(1, activation='sigmoid')(x)\n",
    "model = Model(base_model.input, x)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''model.compile(optimizer='adadelta',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''model.fit(X_train, y_train, batch_size=16, epochs=5, validation_data=(X_val, y_val))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_bottleneck = VGG16(weights='imagenet', include_top=False, pooling=POOLING)\n",
    "train_vgg_bf = vgg_bottleneck.predict(X_train, batch_size=32, verbose=1)\n",
    "valid_vgg_bf = vgg_bottleneck.predict(X_val, batch_size=32, verbose=1)\n",
    "test_vgg_bf = vgg_bottleneck.predict(X_val, batch_size=32, verbose=1)\n",
    "print('VGG train bottleneck features shape: {} size: {:,}'.format(train_vgg_bf.shape, train_vgg_bf.size))\n",
    "print('VGG valid bottleneck features shape: {} size: {:,}'.format(valid_vgg_bf.shape, valid_vgg_bf.size))\n",
    "\n",
    "np.save(open('train_vgg_bf.npy', 'w'), train_vgg_bf)\n",
    "np.save(open('valid_vgg_bf.npy', 'w'), valid_vgg_bf)\n",
    "np.save(open('test_vgg_bf.npy', 'w'), valid_vgg_bf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(multi_class='multinomial', solver='lbfgs', random_state=147)\n",
    "logreg.fit(train_vgg_bf, (y_train * range(Num_Class)).sum(axis=1))\n",
    "valid_probs = logreg.predict_proba(valid_vgg_bf)\n",
    "valid_preds = logreg.predict(valid_vgg_bf)\n",
    "compare_loss['Vgg16']=log_loss(y_val, valid_probs)\n",
    "compare_accuracy['Vgg16']=accuracy_score((y_val * range(Num_Class)).sum(axis=1), valid_preds)\n",
    "print('Validation VGG LogLoss {}'.format(compare_loss['Vgg16']))\n",
    "print('Validation VGG Accuracy {}'.format(compare_accuracy['Vgg16']))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "SVG(model_to_dot(vgg_bottleneck).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "zip([x.name for x in vgg_bottleneck.layers], range(len(vgg_bottleneck.layers)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
