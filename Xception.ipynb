{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "from os import listdir, makedirs\n",
    "from os.path import join, exists, expanduser\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications import xception\n",
    "from keras.applications import inception_v3\n",
    "from keras.applications.vgg16 import preprocess_input, decode_predictions\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "compare_loss={}\n",
    "compare_accuracy={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# function to convert image to array\n",
    "def read_img(address, size):\n",
    "    \"\"\"Read and resize image.\n",
    "    Returns Image as numpy array, by normalizing the values\n",
    "    \"\"\"\n",
    "    img = image.load_img(address, target_size=size)\n",
    "    img = image.img_to_array(img)\n",
    "    return img\n",
    "\n",
    "# function to convert labels to one hot encoding vector\n",
    "def OneHotEncoded(y_train):\n",
    "    y_t=np.zeros((len(y_train),Num_Class), dtype=int)\n",
    "    for i,x in enumerate(y_train):\n",
    "        y_t[i][int(x)]=1\n",
    "    return y_t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "from shutil import copy2\n",
    "INPUT_SIZE = 299\n",
    "directory_lists=os.listdir(\"./imgs/train\")\n",
    "labels = {}\n",
    "data = {}\n",
    "\n",
    "with open('./labels.csv', 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['id','class'])\n",
    "    for i in range(0, len(directory_lists)):                        #'''directory_lists == files in /train == ['c0', 'c1', ... , 'c9']'''\n",
    "        t = directory_lists[i][1:]\n",
    "        imag=os.listdir(\"./imgs/train/\"+str(directory_lists[i]))     #'''imag == files in /train/c# '''\n",
    "        current_loc = \"./imgs/train/\"+str(directory_lists[i])+\"/\"    #'''./imgs/train/c#/'''\n",
    "        for k in range(0, len(imag)):\n",
    "            x=[current_loc+str(imag[k])]+[t]\n",
    "            writer.writerow(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './'\n",
    "labels = pd.read_csv(join(data_dir, 'labels.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22424it [02:33, 146.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Images shape: (22424, 299, 299, 3) size: 6,014,184,072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "INPUT_SIZE = 299\n",
    "POOLING = 'avg'\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "x_train = np.zeros((len(labels), INPUT_SIZE, INPUT_SIZE, 3), dtype='float32')\n",
    "y_train= np.zeros((len(labels),), dtype='float32')\n",
    "\n",
    "for i, img_id in tqdm(enumerate(labels['id'])):\n",
    "    img = read_img(img_id, (INPUT_SIZE, INPUT_SIZE))\n",
    "    x = xception.preprocess_input(np.expand_dims(img.copy(), axis=0))\n",
    "    x_train[i] = x\n",
    "    y_train[i]=int(labels['class'][i])\n",
    "print('Train Images shape: {} size: {:,}'.format(x_train.shape, x_train.size))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0 ..., 0 0 0]\n",
      " [1 0 0 ..., 0 0 0]\n",
      " [1 0 0 ..., 0 0 0]\n",
      " ..., \n",
      " [0 0 0 ..., 0 0 1]\n",
      " [0 0 0 ..., 0 0 1]\n",
      " [0 0 0 ..., 0 0 1]]\n",
      "[[[[-0.66274512 -0.58431375 -0.65490198]\n",
      "   [-0.66274512 -0.58431375 -0.67058825]\n",
      "   [-0.66274512 -0.57647061 -0.68627453]\n",
      "   ..., \n",
      "   [ 0.37254906  1.          0.93725491]\n",
      "   [ 0.45882356  0.99215686  0.90588236]\n",
      "   [ 0.60784316  1.          0.94509804]]\n",
      "\n",
      "  [[-0.65490198 -0.57647061 -0.66274512]\n",
      "   [-0.65490198 -0.57647061 -0.66274512]\n",
      "   [-0.65490198 -0.57647061 -0.66274512]\n",
      "   ..., \n",
      "   [ 0.49803925  0.98431373  0.96078432]\n",
      "   [ 0.63137257  0.98431373  0.96078432]\n",
      "   [ 0.77254903  1.          0.97647059]]\n",
      "\n",
      "  [[-0.65490198 -0.57647061 -0.66274512]\n",
      "   [-0.64705884 -0.56862748 -0.65490198]\n",
      "   [-0.63921571 -0.56078434 -0.63137257]\n",
      "   ..., \n",
      "   [ 0.68627453  0.99215686  1.        ]\n",
      "   [ 0.84313726  0.97647059  1.        ]\n",
      "   [ 0.96862745  0.96862745  1.        ]]\n",
      "\n",
      "  ..., \n",
      "  [[-0.54509807 -0.39607841 -0.34117645]\n",
      "   [-0.52156866 -0.372549   -0.31764704]\n",
      "   [-0.52941179 -0.372549   -0.31764704]\n",
      "   ..., \n",
      "   [-0.84313726 -0.85882354 -0.81960785]\n",
      "   [-0.74117649 -0.75686276 -0.71764708]\n",
      "   [-0.83529413 -0.8509804  -0.81176472]]\n",
      "\n",
      "  [[-0.52941179 -0.38039213 -0.32549018]\n",
      "   [-0.51372552 -0.36470586 -0.3098039 ]\n",
      "   [-0.52156866 -0.36470586 -0.3098039 ]\n",
      "   ..., \n",
      "   [-0.75686276 -0.77254903 -0.73333335]\n",
      "   [-0.68627453 -0.7019608  -0.66274512]\n",
      "   [-0.89019608 -0.90588236 -0.86666667]]\n",
      "\n",
      "  [[-0.51372552 -0.36470586 -0.3098039 ]\n",
      "   [-0.50588238 -0.35686272 -0.30196077]\n",
      "   [-0.52941179 -0.372549   -0.31764704]\n",
      "   ..., \n",
      "   [-0.74117649 -0.75686276 -0.71764708]\n",
      "   [-0.78039217 -0.79607844 -0.75686276]\n",
      "   [-0.94509804 -0.96078432 -0.92156863]]]\n",
      "\n",
      "\n",
      " [[[-0.69411767 -0.59215689 -0.66274512]\n",
      "   [-0.7019608  -0.60000002 -0.67058825]\n",
      "   [-0.7019608  -0.60000002 -0.67058825]\n",
      "   ..., \n",
      "   [ 1.          0.98431373  0.99215686]\n",
      "   [ 1.          0.96078432  0.99215686]\n",
      "   [ 1.          0.95294118  1.        ]]\n",
      "\n",
      "  [[-0.70980394 -0.60784316 -0.67843139]\n",
      "   [-0.70980394 -0.60784316 -0.67843139]\n",
      "   [-0.71764708 -0.6156863  -0.68627453]\n",
      "   ..., \n",
      "   [ 0.99215686  0.99215686  0.99215686]\n",
      "   [ 1.          0.98431373  0.99215686]\n",
      "   [ 1.          0.98431373  0.99215686]]\n",
      "\n",
      "  [[-0.72549021 -0.63921571 -0.7019608 ]\n",
      "   [-0.73333335 -0.64705884 -0.70980394]\n",
      "   [-0.73333335 -0.64705884 -0.70980394]\n",
      "   ..., \n",
      "   [ 0.96862745  1.          0.99215686]\n",
      "   [ 0.94509804  1.          0.99215686]\n",
      "   [ 0.93725491  1.          0.97647059]]\n",
      "\n",
      "  ..., \n",
      "  [[-0.93725491 -0.93725491 -0.95294118]\n",
      "   [-0.94509804 -0.94509804 -0.96078432]\n",
      "   [-0.95294118 -0.95294118 -0.96862745]\n",
      "   ..., \n",
      "   [-0.15294117 -0.20784312 -0.28627449]\n",
      "   [-0.80392158 -0.87450981 -0.92941177]\n",
      "   [-0.81176472 -0.89803922 -0.92941177]]\n",
      "\n",
      "  [[-0.93725491 -0.93725491 -0.95294118]\n",
      "   [-0.94509804 -0.94509804 -0.96078432]\n",
      "   [-0.95294118 -0.95294118 -0.96862745]\n",
      "   ..., \n",
      "   [-0.79607844 -0.83529413 -0.88235295]\n",
      "   [-0.89019608 -0.95294118 -0.97647059]\n",
      "   [-0.85882354 -0.93725491 -0.94509804]]\n",
      "\n",
      "  [[-0.93725491 -0.93725491 -0.95294118]\n",
      "   [-0.94509804 -0.94509804 -0.96078432]\n",
      "   [-0.95294118 -0.95294118 -0.96862745]\n",
      "   ..., \n",
      "   [-0.77254903 -0.80392158 -0.82745099]\n",
      "   [-0.85882354 -0.89803922 -0.92156863]\n",
      "   [-0.9137255  -0.97647059 -0.99215686]]]\n",
      "\n",
      "\n",
      " [[[-0.70980394 -0.60784316 -0.67843139]\n",
      "   [-0.70980394 -0.60784316 -0.67843139]\n",
      "   [-0.70980394 -0.60784316 -0.67843139]\n",
      "   ..., \n",
      "   [ 0.92941177  1.          0.96862745]\n",
      "   [ 0.88235295  1.          0.95294118]\n",
      "   [ 0.8509804   1.          0.94509804]]\n",
      "\n",
      "  [[-0.70980394 -0.60784316 -0.67843139]\n",
      "   [-0.70980394 -0.60784316 -0.67843139]\n",
      "   [-0.70980394 -0.60784316 -0.67843139]\n",
      "   ..., \n",
      "   [ 0.99215686  0.97647059  0.98431373]\n",
      "   [ 0.98431373  0.98431373  0.96862745]\n",
      "   [ 0.96078432  1.          0.95294118]]\n",
      "\n",
      "  [[-0.70980394 -0.60784316 -0.67843139]\n",
      "   [-0.70980394 -0.60784316 -0.67843139]\n",
      "   [-0.70980394 -0.60784316 -0.67843139]\n",
      "   ..., \n",
      "   [ 1.          0.94509804  0.98431373]\n",
      "   [ 1.          0.93725491  0.98431373]\n",
      "   [ 1.          0.93725491  0.98431373]]\n",
      "\n",
      "  ..., \n",
      "  [[-0.93725491 -0.92156863 -0.92941177]\n",
      "   [-0.93725491 -0.92156863 -0.92941177]\n",
      "   [-0.93725491 -0.92156863 -0.92941177]\n",
      "   ..., \n",
      "   [-0.0745098  -0.1607843  -0.38039213]\n",
      "   [-0.0745098  -0.1607843  -0.38039213]\n",
      "   [-0.12156862 -0.21568626 -0.41960782]]\n",
      "\n",
      "  [[-0.96078432 -0.94509804 -0.95294118]\n",
      "   [-0.96078432 -0.94509804 -0.95294118]\n",
      "   [-0.96078432 -0.94509804 -0.95294118]\n",
      "   ..., \n",
      "   [-0.08235294 -0.16862744 -0.38823527]\n",
      "   [-0.06666666 -0.15294117 -0.372549  ]\n",
      "   [-0.13725489 -0.23137254 -0.43529409]]\n",
      "\n",
      "  [[-0.93725491 -0.92156863 -0.92941177]\n",
      "   [-0.93725491 -0.92156863 -0.92941177]\n",
      "   [-0.93725491 -0.92156863 -0.92941177]\n",
      "   ..., \n",
      "   [-0.09803921 -0.18431371 -0.40392154]\n",
      "   [-0.06666666 -0.15294117 -0.372549  ]\n",
      "   [-0.14509803 -0.23921567 -0.44313723]]]\n",
      "\n",
      "\n",
      " ..., \n",
      " [[[-0.7019608  -0.64705884 -0.70980394]\n",
      "   [-0.69411767 -0.63921571 -0.7019608 ]\n",
      "   [-0.68627453 -0.63137257 -0.69411767]\n",
      "   ..., \n",
      "   [-0.92941177 -0.88235295 -0.88235295]\n",
      "   [-0.81960785 -0.62352943 -0.67058825]\n",
      "   [-0.1607843   0.20000005  0.09803927]]\n",
      "\n",
      "  [[-0.7019608  -0.64705884 -0.70980394]\n",
      "   [-0.69411767 -0.63921571 -0.7019608 ]\n",
      "   [-0.68627453 -0.63137257 -0.69411767]\n",
      "   ..., \n",
      "   [-0.86666667 -0.83529413 -0.82745099]\n",
      "   [-0.87450981 -0.69411767 -0.74117649]\n",
      "   [-0.13725489  0.20784318  0.10588241]]\n",
      "\n",
      "  [[-0.7019608  -0.64705884 -0.70980394]\n",
      "   [-0.69411767 -0.63921571 -0.7019608 ]\n",
      "   [-0.68627453 -0.63137257 -0.69411767]\n",
      "   ..., \n",
      "   [-0.82745099 -0.81960785 -0.80392158]\n",
      "   [-0.84313726 -0.67843139 -0.71764708]\n",
      "   [-0.09019607  0.22352946  0.13725495]]\n",
      "\n",
      "  ..., \n",
      "  [[-0.96078432 -0.95294118 -0.99215686]\n",
      "   [-0.96078432 -0.95294118 -0.99215686]\n",
      "   [-0.96078432 -0.95294118 -0.99215686]\n",
      "   ..., \n",
      "   [-0.89019608 -0.93725491 -0.93725491]\n",
      "   [-0.89803922 -0.94509804 -0.94509804]\n",
      "   [-0.86666667 -0.93725491 -0.92941177]]\n",
      "\n",
      "  [[-0.96078432 -0.95294118 -0.99215686]\n",
      "   [-0.96078432 -0.95294118 -0.99215686]\n",
      "   [-0.96078432 -0.95294118 -0.99215686]\n",
      "   ..., \n",
      "   [-0.88235295 -0.95294118 -0.94509804]\n",
      "   [-0.88235295 -0.95294118 -0.94509804]\n",
      "   [-0.86666667 -0.94509804 -0.93725491]]\n",
      "\n",
      "  [[-0.96078432 -0.95294118 -0.99215686]\n",
      "   [-0.96078432 -0.95294118 -0.99215686]\n",
      "   [-0.96078432 -0.95294118 -0.99215686]\n",
      "   ..., \n",
      "   [-0.86666667 -0.93725491 -0.92941177]\n",
      "   [-0.86666667 -0.94509804 -0.93725491]\n",
      "   [-0.86666667 -0.94509804 -0.93725491]]]\n",
      "\n",
      "\n",
      " [[[-0.83529413 -0.75686276 -0.81960785]\n",
      "   [-0.81176472 -0.73333335 -0.79607844]\n",
      "   [-0.81176472 -0.73333335 -0.79607844]\n",
      "   ..., \n",
      "   [ 0.5529412   0.98431373  0.73333335]\n",
      "   [ 0.30196083  0.81176472  0.57647061]\n",
      "   [ 0.45098042  1.          0.78039217]]\n",
      "\n",
      "  [[-0.81960785 -0.74117649 -0.80392158]\n",
      "   [-0.81960785 -0.74117649 -0.80392158]\n",
      "   [-0.81176472 -0.73333335 -0.79607844]\n",
      "   ..., \n",
      "   [-0.96078432 -0.65490198 -0.88235295]\n",
      "   [-1.         -0.7019608  -0.89803922]\n",
      "   [-0.92156863 -0.56862748 -0.73333335]]\n",
      "\n",
      "  [[-0.81176472 -0.73333335 -0.79607844]\n",
      "   [-0.82745099 -0.74901962 -0.81176472]\n",
      "   [-0.81176472 -0.73333335 -0.79607844]\n",
      "   ..., \n",
      "   [-0.00392157  0.18431377 -0.00392157]\n",
      "   [-0.86666667 -0.71764708 -0.86666667]\n",
      "   [-1.         -0.89019608 -0.99215686]]\n",
      "\n",
      "  ..., \n",
      "  [[-0.94509804 -0.93725491 -0.97647059]\n",
      "   [-0.95294118 -0.94509804 -0.98431373]\n",
      "   [-0.96078432 -0.95294118 -0.99215686]\n",
      "   ..., \n",
      "   [-0.93725491 -0.94509804 -0.96078432]\n",
      "   [-0.81176472 -0.81960785 -0.83529413]\n",
      "   [-0.89019608 -0.89803922 -0.9137255 ]]\n",
      "\n",
      "  [[-0.94509804 -0.93725491 -0.97647059]\n",
      "   [-0.95294118 -0.94509804 -0.98431373]\n",
      "   [-0.96078432 -0.95294118 -0.99215686]\n",
      "   ..., \n",
      "   [-0.88235295 -0.89019608 -0.90588236]\n",
      "   [-0.8509804  -0.85882354 -0.87450981]\n",
      "   [-0.65490198 -0.66274512 -0.67843139]]\n",
      "\n",
      "  [[-0.94509804 -0.93725491 -0.97647059]\n",
      "   [-0.95294118 -0.94509804 -0.98431373]\n",
      "   [-0.96078432 -0.95294118 -0.99215686]\n",
      "   ..., \n",
      "   [-0.92156863 -0.92941177 -0.94509804]\n",
      "   [-0.92156863 -0.92941177 -0.94509804]\n",
      "   [-0.89803922 -0.90588236 -0.92156863]]]\n",
      "\n",
      "\n",
      " [[[-0.86666667 -0.8509804  -0.89019608]\n",
      "   [-0.87450981 -0.85882354 -0.89803922]\n",
      "   [-0.88235295 -0.86666667 -0.90588236]\n",
      "   ..., \n",
      "   [-0.63921571 -0.6156863  -0.78039217]\n",
      "   [-0.97647059 -0.98431373 -1.        ]\n",
      "   [-0.81176472 -0.85882354 -0.98431373]]\n",
      "\n",
      "  [[-0.87450981 -0.85882354 -0.89803922]\n",
      "   [-0.87450981 -0.85882354 -0.89803922]\n",
      "   [-0.88235295 -0.86666667 -0.90588236]\n",
      "   ..., \n",
      "   [ 0.27843142  0.43529415  0.23921573]\n",
      "   [ 0.12941182  0.24705887  0.06666672]\n",
      "   [-0.36470586 -0.27058822 -0.42745095]]\n",
      "\n",
      "  [[-0.88235295 -0.86666667 -0.90588236]\n",
      "   [-0.88235295 -0.86666667 -0.90588236]\n",
      "   [-0.88235295 -0.86666667 -0.90588236]\n",
      "   ..., \n",
      "   [ 0.23137259  0.56862748  0.34901965]\n",
      "   [ 0.28627455  0.60000002  0.38823533]\n",
      "   [ 0.35686278  0.66274512  0.45098042]]\n",
      "\n",
      "  ..., \n",
      "  [[-0.82745099 -0.50588238 -0.74117649]\n",
      "   [-0.81960785 -0.51372552 -0.74117649]\n",
      "   [-0.80392158 -0.52156866 -0.72549021]\n",
      "   ..., \n",
      "   [-0.92941177 -0.93725491 -0.95294118]\n",
      "   [-0.92941177 -0.93725491 -0.95294118]\n",
      "   [-0.92941177 -0.93725491 -0.95294118]]\n",
      "\n",
      "  [[-0.83529413 -0.51372552 -0.74901962]\n",
      "   [-0.81960785 -0.51372552 -0.74117649]\n",
      "   [-0.80392158 -0.52156866 -0.72549021]\n",
      "   ..., \n",
      "   [-0.92941177 -0.93725491 -0.95294118]\n",
      "   [-0.92941177 -0.93725491 -0.95294118]\n",
      "   [-0.92941177 -0.93725491 -0.95294118]]\n",
      "\n",
      "  [[-0.83529413 -0.51372552 -0.74901962]\n",
      "   [-0.82745099 -0.50588238 -0.74117649]\n",
      "   [-0.79607844 -0.51372552 -0.71764708]\n",
      "   ..., \n",
      "   [-0.92941177 -0.93725491 -0.95294118]\n",
      "   [-0.92941177 -0.93725491 -0.95294118]\n",
      "   [-0.92941177 -0.93725491 -0.95294118]]]]\n",
      "[[0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " ..., \n",
      " [0 0 1 ..., 0 0 0]\n",
      " [1 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "Num_Class=10  # number of classes in dataset\n",
    "# convert labels to one hot encoding\n",
    "y_train=OneHotEncoded(y_train)\n",
    "print(y_train)\n",
    "# split data in to training and validation set\n",
    "X_train, X_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.33, random_state=42)\n",
    "print(X_train)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15024/15024 [==============================] - 8948s 596ms/step\n",
      "7400/7400 [==============================] - 4337s 586ms/step\n",
      "Xception train bottleneck features shape: (15024, 2048) size: 30,769,152\n",
      "Xception valid bottleneck features shape: (7400, 2048) size: 15,155,200\n"
     ]
    }
   ],
   "source": [
    "# forward passing the training and validation set\n",
    "xception_bottleneck = xception.Xception(weights='imagenet', include_top=False, pooling=POOLING)\n",
    "train_x_bf = xception_bottleneck.predict(X_train, batch_size=32, verbose=1)\n",
    "valid_x_bf = xception_bottleneck.predict(X_val, batch_size=32, verbose=1)\n",
    "print('Xception train bottleneck features shape: {} size: {:,}'.format(train_x_bf.shape, train_x_bf.size))\n",
    "print('Xception valid bottleneck features shape: {} size: {:,}'.format(valid_x_bf.shape, valid_x_bf.size))\n",
    "np.save(open('train_x_bf.npy', 'w'), train_x_bf)\n",
    "np.save(open('valid_x_bf.npy', 'w'), valid_x_bf)\n",
    "\n",
    "np.save('train_x_bf_.npy', train_x_bf) \n",
    "np.save('valid_x_bf_.npy', valid_x_bf) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Xception LogLoss 0.0977869202068\n",
      "Validation Xception Accuracy 0.977837837838\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(multi_class='multinomial', solver='lbfgs', random_state=147)\n",
    "logreg.fit(train_x_bf, (y_train * range(Num_Class)).sum(axis=1))\n",
    "valid_probs = logreg.predict_proba(valid_x_bf)\n",
    "valid_preds = logreg.predict(valid_x_bf)\n",
    "compare_loss['Xception']=log_loss(y_val, valid_probs)\n",
    "compare_accuracy['Xception']=accuracy_score((y_val * range(Num_Class)).sum(axis=1), valid_preds)\n",
    "print('Validation Xception LogLoss {}'.format(compare_loss['Xception']))\n",
    "print('Validation Xception Accuracy {}'.format(compare_accuracy['Xception']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
